Encodings are hard.

Windows NT uses so called wide characters in its APIs and internally. It's basically UTF-16. Those APIs are native, that is, OS does not need to convert anything.
Also there are "ANSI" wrappers, which are actually not ANSI, but various multibyte encodings. They convert everything to UTF-16 and pass it to the wide APIs.
Internally it's represented as something equivalent to MultibyteToWideChar with codepage set to CP_ACP (0).
Which multibyte encoding is used depends on set windows locale (this cannot be changed prior Windows 10 v1903, where an ability to set CP on per-process basis was introduced).

Windows 9x is similar in design: it also has two sets of APIs (with MSLU opt-in): ANSI and Unicode. But internally everything is ANSI, using CP_ACP codepage (which is not a real codepage, but just an alias to the one used by the system).

Oh, and to complicate things a bit further there is OEM encoding (I think this comes mostly from DOS and VGA adapter character set). It is used by default by console (not changable on Win95, changable on NT) and as an opt-on for file APIs (SetFileApisToOEM and SetFileApisToANSI); they both just flip the conversion switches.

Windows 9x apps (mostly) work on NT due to encoding conversions (well, if you set your system codepage right). Implementing this model might be good.

BUT most modern systems and programs prefer UTF-8, not UTF-16 (it is the default GNU/Linux configuration, it is the dominant encoding on the web, it is the encofing used by modern Apple's file systems). This is why I am leaning to using UTF-8 internally.

Wine and ReactOS use UTF-16 (well, this makes sense, as they are trying to very closely approximate windows). uwin strives to increase interoperability with host systems, not emulation precision, so UTF-8 might still be a good idea.

Sooo... This is probably what I will do.

This might be a problem for APIs that are closely coupled to win32 nls (like lstrcmpA or LCMapStringA), they might be an opt-out of this, but other stuff (like file and windowing APIs) should definitely be UTF-8.

For this reason I introduce several notions (and types they project to):
ansi string - a string in current emulated ANSI system codepage (part of system locale) (either single-byte or double-byte)
oem string  - a string in current emulated OEM system codepage (part of system locale) (can this be double-byte)
narrow string - either ansi or oem string in any codepage (depends on context)
wide string - a win nt native UTF-16 string (char16_t and std::u16string should be used, not wchat_t; their size is implementation-defined)
native string - a utf-8 string 

(NOTE: oem and ansi strings should use the same type, as win32 functions are the same for them, it's just the settings that chenges the behaviour)
